<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"
	  xmlns:pref="http://www.w3.org/2002/Math/preference"
      pref:renderer="css">

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<META http-equiv="Content-Style-Type" content="text/css">

<style>
h1,h2,h3,h4,h5 {
    font-family: helvetica, arial, 'sans serif';
    text-align: left;
    color:#000000;
}


p,table,li,dl,address {
    font-family: helvetica, arial, 'sans serif';
    margin-left: 0%;
    margin-right: 3%;
}


ul,ol {
    font-family: helvetica, arial, 'sans serif';
    margin-left: 1em;
    margin-right: 0em;
    font-size: 90%;
}
</style>

<head>
<script language="JavaScript1.8" type="text/javascript"><!--
	pageModDate = "20 April 2013 03:33 PDT";
	// copyright 1997--2013 by P.B. Stark, statistics.berkeley.edu/~stark, and A. Culich, aculich@berkeley.edu
    // All rights reserved.
// -->
</script>

<title>Topic list for Reproducible and Collaborative Data Science</title>
</head>

<body>

<h1>Reproducible and Collaborative Data Science</h1>
<p>Last edited 20 April 2013</p>

<p>
   Here are topics currently being considered for inclusion in a Statistics/CS upper-division course on
   Reproducible and Collaborative Data Science.
   They fall in categories like strategies, styles, hygiene, and best practices;
   software tools; data formats and structures; numerics; and algorithms for common problems.
   The course will be taught using git, IPython Notebook, LaTeX and BibTeX
</p>


<ul>
    <li>Revision control systems: why?</li>
    <li>Introduction to git and github</li>
    <li>Introduction to Python and IPython notebook</li>

    <li>Good coding hygiene</li>
    <li>Code "smells"</li>
    <li>Coding "Style".  Python style</li>
    <li>File formats</li>
    <li>Documentation and comments</li>
    <li>Introduction to LaTeX and BibTeX</li>
    <li>Reproducibility and replicability; levels of reproducibility. </li>
    <li>Coding for Collaboration. Collaborating with your future self</li>

    <li>Parallel computing: MIMD, SIMD, Hadoop, Map-Reduce. inter-process communication</li>
    <li>Cloud computing</li>
    <li>Virtual machines</li>
    <li>Installing software on virtual machines</li>

    <li>Hashes and digests</li>
    <li>Hash chains</li>
    <li>Public key encryption</li>
    <li>Digital signatures</li>

    <li>XML</li>
    <li>Unstructured data</li>
    <li>regular expressions</li>
    <li>Relational databases; SQL</li>

    <li>Pseudo-random number generators</li>
    <li>Tests of PRNGs: DIEHARD battery</li>
    <li>Cryptographically secure PRNGs</li>
    <li>Simulation, reproducible simulation</li>
    <li>The probability transform</li>
    <li>Simulating arbitrary distributions</li>
    <li>Pseudo random sampling. Why does the number of states of a PRNG matter?</li>
    <li>Importance sampling</li>
    <li>MCMC</li>

    <li>Floating point arithmetic</li>
    <li>Machine precision</li>
    <li>Underflow and overflow</li>
    <li>algebraic equality does not imply numerical equality: examples</li>
    <li>Interval arithmetic </li>
    <li>Arbitrary precision arithmetic</li>

    <li>Computational complexity and run times. Expected and worst-case. Linear-time algorithms,
         polynomial-time algorithms, NP-complete.</li>

    <li>Numerical linear algebra</li>
    <li>Condition number</li>
    <li>Solving linear systems: avoid inverses</li>
    <li>The QR decomposition</li>
    <li>Back substitution</li>
    <li>Least squares</li>
    <li>Orthogonalization; the Gram-Schmidt transform</li>
    <li>Eigenvalues, eigenvectors, singular value decomposition </li>
    <li>The power method</li>
    <li>Regularized least squares: ridge regression, truncated SVD</li>

    <li>Numerical integration. Trapezoid method. Monte Carlo integration.</li>
    <li>Numerical differentiation; instability</li>
    <li>Root finding. Newton's method</li>
    <li>Unconstrained optimization: the problem of local minima.
    <li>steepest descent, amoeba, simulated annealing, genetic algorithms</li>
    <li>Convex optimization. local minima attain the global minimum.
    <li>Smooth vs nonsmooth convex problems.
    <li>Failure of steepest descent for nonsmooth convex problems.</li>
    <li>The SDG algorithm for nonsmooth convex problems.</li>
    <li>The BFGS algorithm: low rank approximations to the Hessian</li>
    <li>Convex Constrained optimization: Kuhn-Tucker conditions. </li>
    <li>Linear and quadratic programs. </li>
    <li>Polytopes</li>
    <li>Feasible points, extreme points</li>
    <li>Fundamental theorem of linear programming. </li>
    <li>Simplex method.</li>
    <li>Slack variables. Minimum l_1 problems. LASSO. SVM.</li>
    <li>NNLS and BVLS algorithms</li>

    <li>The FFT. Spectrum estimation: leakage and apodization</li>

    <li>Numerical solution of PDEs: Finite-element, finite-difference; spectral methods</li>
    <li>A posteriori error bounds</li>

    <li>Smoothing, curve-fitting and surface fitting, splines: cubic splines, B-spline basis</li>
    <li>Visualization: plotting, contour plots, mesh plots, false-color plots. Principles and best practices
        for graphical display of data</li>

<ul>

<p>&copy;2013 by P.B. Stark and A. Culich.  All rights reserved.</p>
</body>
</html>